{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNI5sC+HSDrUcMk/i+1UOno",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/willaure/-Web-Scraping-/blob/main/Untitled26.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RqFe0BUpM08x"
      },
      "outputs": [],
      "source": [
        "# Extract information from the given web site\n",
        "# You will extract the data from the below web site:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#this url contains the data you need to scrape\n",
        "url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/datasets/Programming_Languages.html\""
      ],
      "metadata": {
        "id": "ElpKh234SAoy"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The data you need to scrape is the name of the programming language and average annual salary.\n",
        "# It is a good idea to open the url in your web broswer and study the contents of the web page before you start to scrape."
      ],
      "metadata": {
        "id": "w6VL274YU66V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here\n",
        "!pip install requests beautifulsoup4\n",
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUdAPF9Xbc9V",
        "outputId": "e1da4f9c-9199-4461-8874-52765b05bd38"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (4.13.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the webpage at the url"
      ],
      "metadata": {
        "id": "-Yar4knlbi5C"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#your code goes here\n",
        "import requests\n",
        "\n",
        "# Define the URL you want to download\n",
        "url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/datasets/Programming_Languages.html\"  # Replace with your target URL\n",
        "\n",
        "try:\n",
        "    # Send a GET request to the URL\n",
        "    response = requests.get(url)\n",
        "\n",
        "    # Check if the request was successful (status code 200)\n",
        "    if response.status_code == 200:\n",
        "        # Save the webpage content to an HTML file\n",
        "        with open(\"webpage.html\", \"w\", encoding=\"utf-8\") as file:\n",
        "            file.write(response.text)\n",
        "        print(\"Webpage successfully downloaded as 'webpage.html'\")\n",
        "    else:\n",
        "        print(f\"Failed to download. Status code: {response.status_code}\")\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error fetching the URL: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRkAvgUYbqHi",
        "outputId": "ab3a0044-6b67-4d5c-a683-12a88f7cf229"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Webpage successfully downloaded as 'webpage.html'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a soup object"
      ],
      "metadata": {
        "id": "NN8Sk8C5bvFR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#your code goes here\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "with open(\"webpage.html\", \"r\", encoding=\"utf-8\") as file:\n",
        "    soup = BeautifulSoup(file.read(), \"html.parser\")\n",
        "\n",
        "# Now extract data (e.g., language names and salaries)\n",
        "# Example: Find all <div> tags with a specific class\n",
        "data = []\n",
        "for div in soup.find_all(\"div\", class_=\"language-salary-item\"):  # Adjust class name\n",
        "    language = div.find(\"h3\").text.strip()\n",
        "    salary = div.find(\"span\", class_=\"salary\").text.strip()\n",
        "    data.append((language, salary))\n",
        "\n",
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZhi4T4obzNW",
        "outputId": "450a5fd0-90f7-4e12-f442-d91b9e063578"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scrape the `Language name` and `annual average salary`."
      ],
      "metadata": {
        "id": "zK5foinscjMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "# Step 1: Define the URL\n",
        "url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/datasets/Programming_Languages.html\"\n",
        "\n",
        "# Step 2: Fetch the webpage\n",
        "try:\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()  # Raise error if request fails\n",
        "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "except Exception as e:\n",
        "    print(f\"Failed to fetch the page: {e}\")\n",
        "    exit()\n",
        "\n",
        "# Step 3: Find the table - this page has a simple table without classes\n",
        "table = soup.find(\"table\")\n",
        "\n",
        "data = []\n",
        "if table:\n",
        "    # Get all rows except the header\n",
        "    rows = table.find_all(\"tr\")[1:]  # Skip header row\n",
        "\n",
        "    for row in rows:\n",
        "        cols = row.find_all(\"td\")\n",
        "        if len(cols) >= 2:\n",
        "            language = cols[1].text.strip()  # Language is in the second column\n",
        "            salary = cols[3].text.strip()   # Salary is in the fourth column\n",
        "            data.append({\"Language\": language, \"Average Salary\": salary})\n",
        "else:\n",
        "    print(\"No table found in the HTML.\")\n",
        "\n",
        "# Step 4: Save to CSV\n",
        "if data:\n",
        "    df = pd.DataFrame(data)\n",
        "    df.to_csv(\"programming_salaries.csv\", index=False)\n",
        "    print(\"Data saved to 'programming_salaries.csv'\")\n",
        "    print(\"\\nFirst 5 rows of scraped data:\")\n",
        "    print(df.head())\n",
        "else:\n",
        "    print(\"No data was scraped. Check HTML structure.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gEf0LnpdnY6",
        "outputId": "007f8920-e476-4bac-b5ed-b6214fa96e1a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data saved to 'programming_salaries.csv'\n",
            "\n",
            "First 5 rows of scraped data:\n",
            "     Language Average Salary\n",
            "0      Python       $114,383\n",
            "1        Java       $101,013\n",
            "2           R        $92,037\n",
            "3  Javascript       $110,981\n",
            "4       Swift       $130,801\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the scrapped data into a file named popular-languages.csv"
      ],
      "metadata": {
        "id": "SRnzpwxmeCU1"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "# Step 1: Define the URL\n",
        "url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/datasets/Programming_Languages.html\"\n",
        "\n",
        "# Step 2: Fetch the webpage\n",
        "try:\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()  # Raise error if request fails\n",
        "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "except Exception as e:\n",
        "    print(f\"Failed to fetch the page: {e}\")\n",
        "    exit()\n",
        "\n",
        "# Step 3: Find and extract data from the table\n",
        "data = []\n",
        "table = soup.find(\"table\")\n",
        "\n",
        "if table:\n",
        "    # Get all rows except the header\n",
        "    rows = table.find_all(\"tr\")[1:]  # Skip header row\n",
        "\n",
        "    for row in rows:\n",
        "        cols = row.find_all(\"td\")\n",
        "        if len(cols) >= 4:  # Ensure we have enough columns\n",
        "            language = cols[1].text.strip()  # Language is in the second column\n",
        "            salary = cols[3].text.strip()   # Salary is in the fourth column\n",
        "            data.append({\"Language\": language, \"Average Salary\": salary})\n",
        "else:\n",
        "    print(\"No table found in the HTML.\")\n",
        "\n",
        "# Step 4: Save to CSV file named 'popular-languages.csv'\n",
        "if data:\n",
        "    df = pd.DataFrame(data)\n",
        "    df.to_csv(\"popular-languages.csv\", index=False)\n",
        "    print(\"Data successfully saved to 'popular-languages.csv'\")\n",
        "    print(\"\\nFirst 5 rows of the scraped data:\")\n",
        "    print(df.head())\n",
        "else:\n",
        "    print(\"No data was scraped. Check HTML structure.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Y5URb4fd7Vr",
        "outputId": "39e59e27-079b-4f93-bb9c-4b4070ed1668"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data successfully saved to 'popular-languages.csv'\n",
            "\n",
            "First 5 rows of the scraped data:\n",
            "     Language Average Salary\n",
            "0      Python       $114,383\n",
            "1        Java       $101,013\n",
            "2           R        $92,037\n",
            "3  Javascript       $110,981\n",
            "4       Swift       $130,801\n"
          ]
        }
      ]
    }
  ]
}