# -*- coding: utf-8 -*-
"""Untitled26.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NSLjPek_fuNOTXi5kL9qF8-XL2MDh3se
"""

# Extract information from the given web site
# You will extract the data from the below web site:

#this url contains the data you need to scrape
url = "https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/datasets/Programming_Languages.html"

# The data you need to scrape is the name of the programming language and average annual salary.
# It is a good idea to open the url in your web broswer and study the contents of the web page before you start to scrape.

# Your code here
!pip install requests beautifulsoup4
import requests
from bs4 import BeautifulSoup

# Download the webpage at the url

#your code goes here
import requests

# Define the URL you want to download
url = "https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/datasets/Programming_Languages.html"  # Replace with your target URL

try:
    # Send a GET request to the URL
    response = requests.get(url)

    # Check if the request was successful (status code 200)
    if response.status_code == 200:
        # Save the webpage content to an HTML file
        with open("webpage.html", "w", encoding="utf-8") as file:
            file.write(response.text)
        print("Webpage successfully downloaded as 'webpage.html'")
    else:
        print(f"Failed to download. Status code: {response.status_code}")
except requests.exceptions.RequestException as e:
    print(f"Error fetching the URL: {e}")

# Create a soup object

#your code goes here
from bs4 import BeautifulSoup

with open("webpage.html", "r", encoding="utf-8") as file:
    soup = BeautifulSoup(file.read(), "html.parser")

# Now extract data (e.g., language names and salaries)
# Example: Find all <div> tags with a specific class
data = []
for div in soup.find_all("div", class_="language-salary-item"):  # Adjust class name
    language = div.find("h3").text.strip()
    salary = div.find("span", class_="salary").text.strip()
    data.append((language, salary))

print(data)

# Scrape the `Language name` and `annual average salary`.

import requests
from bs4 import BeautifulSoup
import pandas as pd

# Step 1: Define the URL
url = "https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/datasets/Programming_Languages.html"

# Step 2: Fetch the webpage
try:
    response = requests.get(url)
    response.raise_for_status()  # Raise error if request fails
    soup = BeautifulSoup(response.text, "html.parser")
except Exception as e:
    print(f"Failed to fetch the page: {e}")
    exit()

# Step 3: Find the table - this page has a simple table without classes
table = soup.find("table")

data = []
if table:
    # Get all rows except the header
    rows = table.find_all("tr")[1:]  # Skip header row

    for row in rows:
        cols = row.find_all("td")
        if len(cols) >= 2:
            language = cols[1].text.strip()  # Language is in the second column
            salary = cols[3].text.strip()   # Salary is in the fourth column
            data.append({"Language": language, "Average Salary": salary})
else:
    print("No table found in the HTML.")

# Step 4: Save to CSV
if data:
    df = pd.DataFrame(data)
    df.to_csv("programming_salaries.csv", index=False)
    print("Data saved to 'programming_salaries.csv'")
    print("\nFirst 5 rows of scraped data:")
    print(df.head())
else:
    print("No data was scraped. Check HTML structure.")

# Save the scrapped data into a file named popular-languages.csv

import requests
from bs4 import BeautifulSoup
import pandas as pd

# Step 1: Define the URL
url = "https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/datasets/Programming_Languages.html"

# Step 2: Fetch the webpage
try:
    response = requests.get(url)
    response.raise_for_status()  # Raise error if request fails
    soup = BeautifulSoup(response.text, "html.parser")
except Exception as e:
    print(f"Failed to fetch the page: {e}")
    exit()

# Step 3: Find and extract data from the table
data = []
table = soup.find("table")

if table:
    # Get all rows except the header
    rows = table.find_all("tr")[1:]  # Skip header row

    for row in rows:
        cols = row.find_all("td")
        if len(cols) >= 4:  # Ensure we have enough columns
            language = cols[1].text.strip()  # Language is in the second column
            salary = cols[3].text.strip()   # Salary is in the fourth column
            data.append({"Language": language, "Average Salary": salary})
else:
    print("No table found in the HTML.")

# Step 4: Save to CSV file named 'popular-languages.csv'
if data:
    df = pd.DataFrame(data)
    df.to_csv("popular-languages.csv", index=False)
    print("Data successfully saved to 'popular-languages.csv'")
    print("\nFirst 5 rows of the scraped data:")
    print(df.head())
else:
    print("No data was scraped. Check HTML structure.")